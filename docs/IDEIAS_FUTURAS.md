# Roadmap e Ideias Futuras para o Chatbot Ollama

Este documento lista potenciais melhorias e funcionalidades a serem implementadas no projeto.

## Funcionalidades Implementadas (Principais)

*   Integra√ß√£o com API `/api/chat` do Ollama.
*   Interface web b√°sica com Gradio (`gr.Blocks`).
*   Streaming de respostas na UI.
*   Manuten√ß√£o do hist√≥rico de conversa por sess√£o.
*   Sele√ß√£o de modelo Ollama na UI.
*   Salvamento persistente do hist√≥rico de chat em BD SQLite (`chat_history.db`).
*   Pr√©-processamento b√°sico da entrada do usu√°rio (limpeza de espa√ßos).
*   Testes unit√°rios com mock para a integra√ß√£o com Ollama.
*   Teste de integra√ß√£o (marcado como `slow`).
*   Teste unit√°rio para pr√©-processamento.
*   Configura√ß√£o externa via `.env` (URL API, Modelo Padr√£o, N√≠vel de Log).
*   Verifica√ß√£o/Instala√ß√£o autom√°tica de depend√™ncias ao iniciar `app.py`.
*   Exibi√ß√£o do tempo total de resposta na UI.

## Pr√≥ximos Passos e Ideias Futuras

### UI/UX (Interface e Experi√™ncia do Usu√°rio)

*   **[Em Progresso]** Bot√µes de Feedback (üëç/üëé) para as respostas do assistente.
*   Bot√£o "Limpar Chat" para reiniciar a conversa na interface.
*   Exibi√ß√£o de um indicador de "pensando..." ou timer *durante* a gera√ß√£o da resposta (mais complexo com `gr.Blocks`).
*   Permitir configurar par√¢metros do modelo na UI (ex: temperatura, top_p).
*   Adicionar exemplos de prompts iniciais.
*   Melhorar layout e estiliza√ß√£o geral da interface.
*   Exibir mensagens de erro de forma mais amig√°vel na interface.

### Core / Backend

*   **P√≥s-processamento:** Implementar limpeza/formata√ß√£o da resposta do LLM (`src/core/processing.py`).
*   **Expandir Pr√©-processamento:** Adicionar mais regras (ex: normaliza√ß√£o de texto).
*   **RAG (Retrieval-Augmented Generation):**
    *   Implementar busca em base de conhecimento local (ex: arquivos de texto, PDFs) para fornecer contexto adicional ao LLM antes de responder.
    *   Integrar com APIs externas para buscar informa√ß√µes em tempo real (ex: clima, not√≠cias).
*   **Gerenciamento de Contexto:** Implementar estrat√©gias mais avan√ßadas para gerenciar o hist√≥rico enviado ao LLM (ex: sumariza√ß√£o de conversas longas, janelas deslizantes) para evitar exceder limites de contexto.
*   **L√≥gica de Comandos:** Implementar detec√ß√£o de comandos espec√≠ficos na entrada do usu√°rio (ex: `/resumir`, `/buscar`).

### Testes

*   Expandir cobertura de testes unit√°rios, especialmente para novas funcionalidades no `src/core`.
*   Implementar testes de ponta a ponta (e2e) usando ferramentas como Playwright ou Selenium (simulam intera√ß√£o do usu√°rio na interface web).

### Fine-tuning

*   **Prepara√ß√£o de Dados:** Desenvolver scripts para extrair, limpar, anonimizar e formatar os dados do `chat_history.db`.
*   **Sele√ß√£o de Estrat√©gia/Ferramenta:** Escolher a melhor abordagem (local com `trl`, servi√ßo de nuvem, etc.) com base nos recursos e objetivos.
*   **Execu√ß√£o e Avalia√ß√£o:** Realizar o fine-tuning e avaliar o desempenho do modelo customizado.
*   **Integra√ß√£o (Opcional):** Integrar o modelo ajustado de volta √† aplica√ß√£o (ex: importando no Ollama, se poss√≠vel).

### Deploy e Opera√ß√µes

*   **Dockeriza√ß√£o:** Criar um `Dockerfile` para empacotar a aplica√ß√£o e suas depend√™ncias, facilitando o deploy.
*   **Configura√ß√£o de Ambientes:** Estruturar melhor a configura√ß√£o para diferentes ambientes (dev, prod).
*   **Monitoramento:** Adicionar monitoramento b√°sico da aplica√ß√£o (ex: sa√∫de, uso de recursos). 